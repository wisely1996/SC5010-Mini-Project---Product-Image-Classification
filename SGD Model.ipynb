{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cfung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "C:\\Users\\cfung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "C:\\Users\\cfung\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import itertools\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img \n",
    "from keras.models import Sequential \n",
    "from keras import optimizers\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense \n",
    "from keras import applications \n",
    "from keras.utils.np_utils import to_categorical \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "%matplotlib inline\n",
    "import math \n",
    "import datetime\n",
    "import time\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14628\\3930989819.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_top.loc[:,\"class\"] = 0\n",
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_14628\\3930989819.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_btm.loc[:,\"class\"] = 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>6ed9c2a655d6f84badb557bc210c1fb5.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>234</th>\n",
       "      <td>293c5038f681f017254800819a968212.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8238</th>\n",
       "      <td>90e1e6fbaa0c9a69ad0ee70bc2ea251d.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2708</th>\n",
       "      <td>42ea56b9983ba2bf7e01acf5dda172f5.jpg</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7671</th>\n",
       "      <td>f13b80836fbe7c635a9817e121093594.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9880</th>\n",
       "      <td>b61f5b0aec4375090b5a268a1f516ead.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>5072c6fb5ab3ae57524639805321a0f4.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>b2afaca110148bc0710f828c9d53b39f.jpg</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6834</th>\n",
       "      <td>3511390df751f1c8c70ca9c6897ddfc5.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9306</th>\n",
       "      <td>026f054380bff76064f26bcb2628ff40.jpg</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9094 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  filename  category\n",
       "9817  6ed9c2a655d6f84badb557bc210c1fb5.jpg        29\n",
       "234   293c5038f681f017254800819a968212.jpg         3\n",
       "8238  90e1e6fbaa0c9a69ad0ee70bc2ea251d.jpg        29\n",
       "2708  42ea56b9983ba2bf7e01acf5dda172f5.jpg        28\n",
       "7671  f13b80836fbe7c635a9817e121093594.jpg         4\n",
       "...                                    ...       ...\n",
       "9880  b61f5b0aec4375090b5a268a1f516ead.jpg        29\n",
       "2601  5072c6fb5ab3ae57524639805321a0f4.jpg         3\n",
       "2018  b2afaca110148bc0710f828c9d53b39f.jpg         3\n",
       "6834  3511390df751f1c8c70ca9c6897ddfc5.jpg         4\n",
       "9306  026f054380bff76064f26bcb2628ff40.jpg        29\n",
       "\n",
       "[9094 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df_top = df[(df[\"category\"] == 3)|(df[\"category\"] == 28)]\n",
    "df_top.loc[:,\"class\"] = 0\n",
    "df_btm = df[(df[\"category\"] == 4)|(df[\"category\"] == 29)]\n",
    "df_btm.loc[:,\"class\"] = 1\n",
    "\n",
    "df_cloth = pd.concat([df_top,df_btm]).reset_index(drop = True)\n",
    "df_cloth\n",
    "\n",
    "X = df_cloth[[\"filename\",\"category\"]]\n",
    "y = pd.DataFrame(df_cloth[\"class\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 5010)\n",
    "\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7275, 2), (1819, 2), (7275, 1), (1819, 1))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X1 = X_train[[\"filename\",\"category\"]]\n",
    "y1 = pd.DataFrame(y_train[\"class\"])\n",
    "\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size = 0.2, random_state = 5010)\n",
    "X1_train.shape, X1_test.shape, y1_train.shape, y1_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3803, 3472, 957, 862)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "train_path1 = \"train_dataset\"\n",
    "validation_path1 = \"validation_dataset\"\n",
    "\n",
    "len(os.listdir(train_path1 + '/top')), len(os.listdir(train_path1 + '/btm')), len(os.listdir(validation_path1 + '/top')), len(os.listdir(validation_path1 + '/btm'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7275 images belonging to 2 classes.\n",
      "Found 1819 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "IMG_SIZE = (299, 299)\n",
    "shift = 0.2\n",
    "\n",
    "training_datagen1 = ImageDataGenerator(\n",
    "      rescale = 1./255,\n",
    "      rotation_range=5,\n",
    "      brightness_range=[0.2,1.5],\n",
    "      width_shift_range=shift, \n",
    "      height_shift_range=shift,\n",
    "      horizontal_flip=True)\n",
    "train_set1 = training_datagen1.flow_from_directory(\n",
    "     train_path1,\n",
    "     seed=9,\n",
    "\t   target_size=IMG_SIZE,\n",
    "     class_mode = \"categorical\")\n",
    "validation_datagen1 = ImageDataGenerator(\n",
    "      rescale = 1./255)\n",
    "val_set1 = validation_datagen1.flow_from_directory(\n",
    "\t  validation_path1,\n",
    "\t  target_size=IMG_SIZE,\n",
    "    shuffle=False,\n",
    "    seed=9,\n",
    "    class_mode = \"categorical\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_16 (Conv2D)          (None, 297, 297, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_16 (MaxPoolin  (None, 148, 148, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 144, 144, 64)      51264     \n",
      "                                                                 \n",
      " max_pooling2d_17 (MaxPoolin  (None, 72, 72, 64)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 68, 68, 128)       204928    \n",
      "                                                                 \n",
      " max_pooling2d_18 (MaxPoolin  (None, 34, 34, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 32, 32, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_19 (MaxPoolin  (None, 16, 16, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_4 (Flatten)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 32768)             0         \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 512)               16777728  \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 2)                 514       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 17,314,242\n",
      "Trainable params: 17,314,242\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "# Model 6 new data\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=IMG_SIZE+(3,)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax') \n",
    "])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1011 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_path = \"test_dataset\"\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "      rescale = 1./255)\n",
    "test_data = test_datagen.flow_from_directory(\n",
    "\t  test_path,\n",
    "\t  target_size=IMG_SIZE,\n",
    "        shuffle=False,\n",
    "        seed=9,\n",
    "        class_mode = \"categorical\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'btm': 0, 'top': 1}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the class labels for the training data, in the original order \n",
    "train_labels = train_set1.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "train_labels = to_categorical(train_labels, num_classes=2)    \n",
    "\n",
    "# get the class labels for the training data, in the original order \n",
    "test_labels = test_data.classes \n",
    " \n",
    "# convert the training labels to categorical vectors \n",
    "test_labels = to_categorical(test_labels, num_classes=2)\n",
    "\n",
    "test_data.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#To get better visual of the confusion matrix:\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "   normalize=False,\n",
    "   title='Confusion matrix',\n",
    "   cmap=plt.cm.Blues):\n",
    " \n",
    "#Add Normalization Option\n",
    "\n",
    "   if normalize:\n",
    "     cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "     print('Normalized confusion matrix')\n",
    "   else:\n",
    "     print('Confusion matrix, without normalization')\n",
    " \n",
    "# print(cm)\n",
    " \n",
    "   plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "   plt.title(title)\n",
    "   plt.colorbar()\n",
    "   tick_marks = np.arange(len(classes))\n",
    "   plt.xticks(tick_marks, classes, rotation=45)\n",
    "   plt.yticks(tick_marks, classes)\n",
    " \n",
    "   fmt = '.2f' if normalize else 'd'\n",
    "   thresh = cm.max() / 2.\n",
    "   for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "      plt.text(j, i, format(cm[i, j], fmt), horizontalalignment='center', color='white' if cm[i, j] > thresh else 'black')\n",
    " \n",
    "   plt.tight_layout()\n",
    "   plt.ylabel('True label')\n",
    "   plt.xlabel('Predicted label') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "228/228 [==============================] - 510s 2s/step - loss: 0.6937 - accuracy: 0.4907 - val_loss: 0.6914 - val_accuracy: 0.5481\n",
      "Epoch 2/20\n",
      "228/228 [==============================] - 517s 2s/step - loss: 0.6926 - accuracy: 0.5196 - val_loss: 0.6900 - val_accuracy: 0.5673\n",
      "Epoch 3/20\n",
      "228/228 [==============================] - 493s 2s/step - loss: 0.6919 - accuracy: 0.5282 - val_loss: 0.6889 - val_accuracy: 0.5761\n",
      "Epoch 4/20\n",
      "228/228 [==============================] - 457s 2s/step - loss: 0.6920 - accuracy: 0.5289 - val_loss: 0.6877 - val_accuracy: 0.5899\n",
      "Epoch 5/20\n",
      "228/228 [==============================] - 461s 2s/step - loss: 0.6908 - accuracy: 0.5438 - val_loss: 0.6866 - val_accuracy: 0.5794\n",
      "Epoch 6/20\n",
      "228/228 [==============================] - 456s 2s/step - loss: 0.6903 - accuracy: 0.5542 - val_loss: 0.6857 - val_accuracy: 0.6031\n",
      "Epoch 7/20\n",
      "228/228 [==============================] - 452s 2s/step - loss: 0.6895 - accuracy: 0.5509 - val_loss: 0.6846 - val_accuracy: 0.6135\n",
      "Epoch 8/20\n",
      "228/228 [==============================] - 455s 2s/step - loss: 0.6886 - accuracy: 0.5713 - val_loss: 0.6835 - val_accuracy: 0.6157\n",
      "Epoch 9/20\n",
      "228/228 [==============================] - 452s 2s/step - loss: 0.6880 - accuracy: 0.5729 - val_loss: 0.6825 - val_accuracy: 0.6223\n",
      "Epoch 10/20\n",
      "228/228 [==============================] - 452s 2s/step - loss: 0.6872 - accuracy: 0.5740 - val_loss: 0.6814 - val_accuracy: 0.6295\n",
      "Epoch 11/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6869 - accuracy: 0.5779 - val_loss: 0.6802 - val_accuracy: 0.6311\n",
      "Epoch 12/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6860 - accuracy: 0.5863 - val_loss: 0.6792 - val_accuracy: 0.6520\n",
      "Epoch 13/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6849 - accuracy: 0.5922 - val_loss: 0.6779 - val_accuracy: 0.6427\n",
      "Epoch 14/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6843 - accuracy: 0.5960 - val_loss: 0.6766 - val_accuracy: 0.6520\n",
      "Epoch 15/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6834 - accuracy: 0.6011 - val_loss: 0.6752 - val_accuracy: 0.6614\n",
      "Epoch 16/20\n",
      "228/228 [==============================] - 449s 2s/step - loss: 0.6831 - accuracy: 0.6026 - val_loss: 0.6737 - val_accuracy: 0.6625\n",
      "Epoch 17/20\n",
      "228/228 [==============================] - 449s 2s/step - loss: 0.6819 - accuracy: 0.6001 - val_loss: 0.6721 - val_accuracy: 0.6586\n",
      "Epoch 18/20\n",
      "228/228 [==============================] - 450s 2s/step - loss: 0.6806 - accuracy: 0.6082 - val_loss: 0.6704 - val_accuracy: 0.6564\n",
      "Epoch 19/20\n",
      "228/228 [==============================] - 449s 2s/step - loss: 0.6789 - accuracy: 0.6238 - val_loss: 0.6685 - val_accuracy: 0.6575\n",
      "Epoch 20/20\n",
      "228/228 [==============================] - 448s 2s/step - loss: 0.6781 - accuracy: 0.6213 - val_loss: 0.6665 - val_accuracy: 0.6570\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 50\n",
    "INIT_LR = 1e-4\n",
    "# Model 6 new data\n",
    "\n",
    "model1 = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=IMG_SIZE+(3,)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2), \n",
    "    tf.keras.layers.Conv2D(64, (5,5), activation='relu'), \n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (5,5), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax') \n",
    "])\n",
    "\n",
    "# model1.summary()\n",
    "\n",
    "model1.compile(\n",
    "    optimizer= tf.keras.optimizers.SGD(\n",
    "        learning_rate=INIT_LR, \n",
    "        decay=INIT_LR / EPOCHS),\n",
    "    loss=keras.losses.categorical_crossentropy,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "H1 = model1.fit(\n",
    "    train_set1, \n",
    "    epochs=20, \n",
    "    validation_data=val_set1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"SGD_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 15s 460ms/step - loss: 0.6651 - accuracy: 0.6795\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6650993824005127, 0.6795251965522766]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model1 = keras.models.load_model(f'SGD_model.h5')\n",
    "\n",
    "model1.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         btm       0.69      0.66      0.68       507\n",
      "         top       0.67      0.69      0.68       504\n",
      "\n",
      "   micro avg       0.68      0.68      0.68      1011\n",
      "   macro avg       0.68      0.68      0.68      1011\n",
      "weighted avg       0.68      0.68      0.68      1011\n",
      " samples avg       0.68      0.68      0.68      1011\n",
      "\n",
      "Confusion matrix, without normalization\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "classificationlabels = [\"top\", \"btm\"]\n",
    "\n",
    "preds1 = np.round(model1.predict(test_data),0)\n",
    "classification_metrics = metrics.classification_report(test_labels, preds1, target_names=classificationlabels)\n",
    "print(classification_metrics)\n",
    "\n",
    "categorical_test_labels = pd.DataFrame(test_labels).idxmax(axis=1)\n",
    "categorical_preds1 = pd.DataFrame(preds1).idxmax(axis=1)\n",
    "confusion_matrix2 = confusion_matrix(categorical_test_labels, categorical_preds1)\n",
    "\n",
    "\n",
    "plot_confusion_matrix(confusion_matrix2, ['top','btm'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aecd030d4c8316a52bf122072e28f84bcc79844c2684e041fef2e3f1d9f59078"
  },
  "kernelspec": {
   "display_name": "Python 3.10.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
